{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beer Hunting with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook we’ll look at some simple data manipulation with Python using the ‘pandas’ package on a large beer review dataset. We’ll use some basic functions to dissect and subset the a .csv file on the hunt for the perfect python pint."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Python2png.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For us who are new to Python, pandas is a great tool for making the step from using Microsoft Excel for data table manipulation to manipulating and analysing data tables (or data frames) with python. On the pandas website it says; ‘pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.’ We’ll use pandas to play around with the beer dataset.\n",
    "\n",
    "For the next bit let’s have a look at the pandas package and how we can use it to manipulate data in a table or ‘Data Frame’ (pandas is dependent on the NumPy package so if you wish to use pandas you’ll also need to install NumPy). We will use a .csv (comma separated value) file which contains 1.5 million reviews and information on different beers (!!!!). This dataset is going to be accessed online from 'data.world' but will be read into our code in a similar way that you would read a file from your own local drive."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/beer-ja.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we bring in a .csv file we must first import pandas into our code as seen below. We simply write in ‘import pandas as pd’ to bring this package and associated modules into our workspace. You’ll notice that the import line also reads ‘as pd’ which means we are giving pandas an alias name. Whenever you see pd in the code you now know we are referencing pandas (this is a pretty universal way of representing pandas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read in the .csv file, we need to assign it a name (we’ll use ‘df’ for data frame) and then use the pandas module ‘read_csv()’. The location of the .csv file goes inside the brackets of the module so pandas knows where to look for the file. If the file was saved on my computer I would just insert the filepath of the .csv. We’re going to also use the pandas module ‘.head()’ on our data frame df to access the first 5 rows of our .csv file and print the output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Queen.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   brewery_id             brewery_name  review_time  review_overall  \\\n",
      "0       10325          Vecchio Birraio   1234817823             1.5   \n",
      "1       10325          Vecchio Birraio   1235915097             3.0   \n",
      "2       10325          Vecchio Birraio   1235916604             3.0   \n",
      "3       10325          Vecchio Birraio   1234725145             3.0   \n",
      "4        1075  Caldera Brewing Company   1293735206             4.0   \n",
      "\n",
      "   review_aroma  review_appearance review_profilename  \\\n",
      "0           2.0                2.5            stcules   \n",
      "1           2.5                3.0            stcules   \n",
      "2           2.5                3.0            stcules   \n",
      "3           3.0                3.5            stcules   \n",
      "4           4.5                4.0     johnmichaelsen   \n",
      "\n",
      "                       beer_style  review_palate  review_taste  \\\n",
      "0                      Hefeweizen            1.5           1.5   \n",
      "1              English Strong Ale            3.0           3.0   \n",
      "2          Foreign / Export Stout            3.0           3.0   \n",
      "3                 German Pilsener            2.5           3.0   \n",
      "4  American Double / Imperial IPA            4.0           4.5   \n",
      "\n",
      "                beer_name  beer_abv  beer_beerid  \n",
      "0            Sausa Weizen       5.0        47986  \n",
      "1                Red Moon       6.2        48213  \n",
      "2  Black Horse Black Beer       6.5        48215  \n",
      "3              Sausa Pils       5.0        47969  \n",
      "4           Cauldron DIPA       7.7        64883  \n"
     ]
    }
   ],
   "source": [
    "#this first line imports pandas package as alias pd\n",
    "import pandas as pd\n",
    "\n",
    "#this next line uses pandas '.read_csv()' module to read file as df\n",
    "df = pd.read_csv('https://query.data.world/s/zhsp6ytp4wfqkqq3vdp2eo5fq255sk')\n",
    "\n",
    "#this line prints the first 5 rows in the data frame df\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this code is the first 5 rows of our data frame, confirming that the .csv was read correctly. We can see all the columns here in this view as well but there is a better way to view what data our data frame is comprised off. We can use the modules ‘.shape’ to get the dimensions of our table and ‘.info()’ to get the amount of rows populated for each column and the column data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1586614, 13)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1586614 entries, 0 to 1586613\n",
      "Data columns (total 13 columns):\n",
      "brewery_id            1586614 non-null int64\n",
      "brewery_name          1586599 non-null object\n",
      "review_time           1586614 non-null int64\n",
      "review_overall        1586614 non-null float64\n",
      "review_aroma          1586614 non-null float64\n",
      "review_appearance     1586614 non-null float64\n",
      "review_profilename    1586266 non-null object\n",
      "beer_style            1586614 non-null object\n",
      "review_palate         1586614 non-null float64\n",
      "review_taste          1586614 non-null float64\n",
      "beer_name             1586614 non-null object\n",
      "beer_abv              1518829 non-null float64\n",
      "beer_beerid           1586614 non-null int64\n",
      "dtypes: float64(6), int64(3), object(4)\n",
      "memory usage: 157.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#printing the shape of the dataframe shows us the table dimensions\n",
    "print(df.shape)\n",
    "\n",
    "#printing the info of the dataframe shows us the data type and the amount of missing values for each column\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the shape module we can see that ‘df’ has 13 columns and 1,586,614 rows, which would make opening and playing with this file in Excel an extremely arduous job. From the ‘info()’ module we can see the data types for each column and the amount of ‘non-null’ values. The columns ‘brewery_name’, ‘review_profilename’ and ‘beer_abv’ seem to be missing some data. In pandas we can drop rows that are missing data by using the ‘.dropna()’ module on the original data frame. Here we’ll assign a new name to this data frame called ‘df_drop’."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/obama.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1518478 entries, 0 to 1586613\n",
      "Data columns (total 13 columns):\n",
      "brewery_id            1518478 non-null int64\n",
      "brewery_name          1518478 non-null object\n",
      "review_time           1518478 non-null int64\n",
      "review_overall        1518478 non-null float64\n",
      "review_aroma          1518478 non-null float64\n",
      "review_appearance     1518478 non-null float64\n",
      "review_profilename    1518478 non-null object\n",
      "beer_style            1518478 non-null object\n",
      "review_palate         1518478 non-null float64\n",
      "review_taste          1518478 non-null float64\n",
      "beer_name             1518478 non-null object\n",
      "beer_abv              1518478 non-null float64\n",
      "beer_beerid           1518478 non-null int64\n",
      "dtypes: float64(6), int64(3), object(4)\n",
      "memory usage: 162.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#creating a new data frame called df_drop which has all the row with missing data removed\n",
    "df_drop=df.dropna()\n",
    "\n",
    "#printing the info of the new dataframe\n",
    "print(df_drop.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output now we can see that we have dropped our amount of rows from 1,586,614 down to 1,518,478, but at least we now have a fully populated dataset. If you look back at the ‘.head()’ output you should notice that the ‘review_time’ column is made up of long, large numbers with the data type ‘int64’. This is called ‘epoch time’ which is the time in seconds since Jan 1st 1970 so unless you’re really good at dividing by 60 this data is effectively useless for us. However pandas has a way to convert the int64 data type into a ‘DateTime’ datatype."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/maxresdefault.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brewery_id                     int64\n",
      "brewery_name                  object\n",
      "review_time           datetime64[ns]\n",
      "review_overall               float64\n",
      "review_aroma                 float64\n",
      "review_appearance            float64\n",
      "review_profilename            object\n",
      "beer_style                    object\n",
      "review_palate                float64\n",
      "review_taste                 float64\n",
      "beer_name                     object\n",
      "beer_abv                     float64\n",
      "beer_beerid                    int64\n",
      "dtype: object\n",
      "0   2009-02-16 20:57:03\n",
      "1   2009-03-01 13:44:57\n",
      "2   2009-03-01 14:10:04\n",
      "3   2009-02-15 19:12:25\n",
      "4   2010-12-30 18:53:26\n",
      "Name: review_time, dtype: datetime64[ns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#putting the column name in quotation marks and square brackets directly after the data frame calls out that column \n",
    "#only, and using #pd.to_datetime() on our 'review time' column(with units as seconds) we can convert the whole \n",
    "#column to datetime\n",
    "df_drop['review_time']=pd.to_datetime(df_drop['review_time'],unit='s')\n",
    "\n",
    "#printing out the new and updated data types and the column head\n",
    "print(df_drop.dtypes)\n",
    "print(df_drop['review_time'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ‘review_time’ column now has readable dates and can easily be understood by anyone. The next thing I wanna do is have a look at what all the different types of beer, or the different categories in the ‘beer_style’ column. To do that we need to call out the column ‘beer_style’ from the data frame and use the ‘.unique()’ module to see the different beers, and the ‘.count_values()’ to see the amount of each different beer. This goes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hefeweizen' 'English Strong Ale' 'Foreign / Export Stout'\n",
      " 'German Pilsener' 'American Double / Imperial IPA' 'Herbed / Spiced Beer'\n",
      " 'Light Lager' 'Oatmeal Stout' 'American Pale Lager' 'Rauchbier'\n",
      " 'American Pale Ale (APA)' 'American Porter' 'Belgian Strong Dark Ale'\n",
      " 'American IPA' 'Russian Imperial Stout' 'American Amber / Red Ale'\n",
      " 'American Strong Ale' 'Märzen / Oktoberfest' 'American Adjunct Lager'\n",
      " 'American Blonde Ale' 'Euro Pale Lager' 'English Brown Ale'\n",
      " 'Fruit / Vegetable Beer' 'Belgian Pale Ale' 'English Bitter'\n",
      " 'English Porter' 'Irish Dry Stout' 'American Barleywine'\n",
      " 'American Double / Imperial Stout' 'Doppelbock' 'American Stout'\n",
      " 'Maibock / Helles Bock' 'Dortmunder / Export Lager' 'Euro Strong Lager'\n",
      " 'Low Alcohol Beer' 'Extra Special / Strong Bitter (ESB)' 'Bock'\n",
      " 'English India Pale Ale (IPA)' 'Altbier' 'Kölsch' 'Pumpkin Ale'\n",
      " 'Rye Beer' 'American Pale Wheat Ale' 'Milk / Sweet Stout' 'Schwarzbier'\n",
      " 'Munich Dunkel Lager' 'Vienna Lager' 'American Amber / Red Lager'\n",
      " 'Scottish Ale' 'Witbier' 'American Black Ale' 'Saison / Farmhouse Ale'\n",
      " 'English Barleywine' 'California Common / Steam Beer' 'Euro Dark Lager'\n",
      " 'Scotch Ale / Wee Heavy' 'English Pale Ale' 'Belgian Strong Pale Ale'\n",
      " 'Tripel' 'Flanders Oud Bruin' 'American Brown Ale' 'Smoked Beer' 'Dubbel'\n",
      " 'Dunkelweizen' 'Keller Bier / Zwickel Bier' 'Winter Warmer'\n",
      " 'Bière de Garde' 'Belgian Dark Ale' 'Irish Red Ale' 'Chile Beer'\n",
      " 'English Stout' 'Czech Pilsener' 'Belgian IPA' 'Cream Ale' 'Black & Tan'\n",
      " 'English Dark Mild Ale' 'American Wild Ale' 'Weizenbock'\n",
      " 'American Double / Imperial Pilsner'\n",
      " 'Scottish Gruit / Ancient Herbed Ale' 'Wheatwine'\n",
      " 'American Dark Wheat Ale' 'American Malt Liquor' 'Munich Helles Lager'\n",
      " 'Kristalweizen' 'English Pale Mild Ale' 'Baltic Porter' 'Old Ale'\n",
      " 'Quadrupel (Quad)' 'Braggot' 'Lambic - Fruit' 'Lambic - Unblended'\n",
      " 'Eisbock' 'Flanders Red Ale' 'Berliner Weissbier' 'Kvass' 'Roggenbier'\n",
      " 'Faro' 'Gueuze' 'Gose' 'Japanese Rice Lager' 'Happoshu' 'Sahti'\n",
      " 'Bière de Champagne / Bière Brut']\n",
      "American IPA                        113144\n",
      "American Double / Imperial IPA       85105\n",
      "American Pale Ale (APA)              58072\n",
      "Russian Imperial Stout               53424\n",
      "American Double / Imperial Stout     50137\n",
      "                                     ...  \n",
      "English Pale Mild Ale                  648\n",
      "Faro                                   608\n",
      "Roggenbier                             395\n",
      "Happoshu                               237\n",
      "Kvass                                  229\n",
      "Name: beer_style, Length: 104, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#using the .unique() module we can see the unique variables in the column 'beer_style'\n",
    "print(df_drop['beer_style'].unique())\n",
    "\n",
    "#using .value_counts() on the column we return how many different variables are in the beer style column\n",
    "print(df_drop['beer_style'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are a large number of beers in here, 104 to be exact! This can be seen at the bottom of the output where ‘Length: 104’. Hmm looking at the list there’s a lot of fancy beers on there and a lot I probably wouldn’t walk out of a bottleo with. The next thing I’m going to do is subset the data frame into two seperate ones. One that contains beers that have the word ‘Ale’ in their name and another that contains the string ‘IPA’ in their name. To select columns on with these attributes I’ll use ‘.str.contains()’."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/06-baby-beer.w1200.h630.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 482420 entries, 1 to 1586613\n",
      "Data columns (total 13 columns):\n",
      "brewery_id            482420 non-null int64\n",
      "brewery_name          482420 non-null object\n",
      "review_time           482420 non-null datetime64[ns]\n",
      "review_overall        482420 non-null float64\n",
      "review_aroma          482420 non-null float64\n",
      "review_appearance     482420 non-null float64\n",
      "review_profilename    482420 non-null object\n",
      "beer_style            482420 non-null object\n",
      "review_palate         482420 non-null float64\n",
      "review_taste          482420 non-null float64\n",
      "beer_name             482420 non-null object\n",
      "beer_abv              482420 non-null float64\n",
      "beer_beerid           482420 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(6), int64(2), object(4)\n",
      "memory usage: 51.5+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 225825 entries, 4 to 1586599\n",
      "Data columns (total 13 columns):\n",
      "brewery_id            225825 non-null int64\n",
      "brewery_name          225825 non-null object\n",
      "review_time           225825 non-null datetime64[ns]\n",
      "review_overall        225825 non-null float64\n",
      "review_aroma          225825 non-null float64\n",
      "review_appearance     225825 non-null float64\n",
      "review_profilename    225825 non-null object\n",
      "beer_style            225825 non-null object\n",
      "review_palate         225825 non-null float64\n",
      "review_taste          225825 non-null float64\n",
      "beer_name             225825 non-null object\n",
      "beer_abv              225825 non-null float64\n",
      "beer_beerid           225825 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(6), int64(2), object(4)\n",
      "memory usage: 24.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#creating seperate subset data frames from our original data frame\n",
    "ale = df_drop[df_drop['beer_style'].str.contains('Ale')]\n",
    "IPA = df_drop[df_drop['beer_style'].str.contains('IPA')]\n",
    "\n",
    "#printing the info on both new data frames\n",
    "print(ale.info())\n",
    "print(IPA.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two seperate data frames that contain all the information for beer types containing the word ‘Ale’ and one for the text ‘IPA’. When we have two data frames we can combine them by using pandas join, merge or concatenate modules. I want to combine them both into one for further analysis. Here I’m going to create a new data frame by concatenating the two, which effectively means I’ll just add the rows of one data frame straight onto the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 708245 entries, 1 to 1586599\n",
      "Data columns (total 13 columns):\n",
      "brewery_id            708245 non-null int64\n",
      "brewery_name          708245 non-null object\n",
      "review_time           708245 non-null datetime64[ns]\n",
      "review_overall        708245 non-null float64\n",
      "review_aroma          708245 non-null float64\n",
      "review_appearance     708245 non-null float64\n",
      "review_profilename    708245 non-null object\n",
      "beer_style            708245 non-null object\n",
      "review_palate         708245 non-null float64\n",
      "review_taste          708245 non-null float64\n",
      "beer_name             708245 non-null object\n",
      "beer_abv              708245 non-null float64\n",
      "beer_beerid           708245 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(6), int64(2), object(4)\n",
      "memory usage: 75.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#creating a new data frame titled fav_beer and using pd.concat() to concatenate them\n",
    "fav_beer = pd.concat([ale, IPA])\n",
    "\n",
    "#printing the info to see new data frame\n",
    "print(fav_beer.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that the rows for both data frame ‘ale’ and ‘IPA’ have been concatenated by their rows, which means I have a new data frame for my favourite beer types. However, there may be some beer types that contained both the text ‘Ale’ and ‘IPA’ in the ‘beer_style’ column. Therefore the rows would have been duplicated in the new data frame. Fortunately we can use pandas to see how many duplicates there are in our data frame and remove them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/C-658VsXoAo3ovC.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    692908\n",
      "True      15337\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 692908 entries, 1 to 1586599\n",
      "Data columns (total 13 columns):\n",
      "brewery_id            692908 non-null int64\n",
      "brewery_name          692908 non-null object\n",
      "review_time           692908 non-null datetime64[ns]\n",
      "review_overall        692908 non-null float64\n",
      "review_aroma          692908 non-null float64\n",
      "review_appearance     692908 non-null float64\n",
      "review_profilename    692908 non-null object\n",
      "beer_style            692908 non-null object\n",
      "review_palate         692908 non-null float64\n",
      "review_taste          692908 non-null float64\n",
      "beer_name             692908 non-null object\n",
      "beer_abv              692908 non-null float64\n",
      "beer_beerid           692908 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(6), int64(2), object(4)\n",
      "memory usage: 74.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#using .duplicated() returns a Boolean Series (True or False) for our rows, and .value_counts() shows us how \n",
    "#many are duplicated\n",
    "print(fav_beer.duplicated().value_counts())\n",
    "\n",
    "#create a new data frame and use .drop_duplicates() to remove\n",
    "fav_beer_clean = fav_beer.drop_duplicates()\n",
    "\n",
    "#print out the info on the new data frame\n",
    "print(fav_beer_clean.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see we had 15337 duplicate rows in our data frame ‘fav_beer’. Using ‘.drop_duplicates()’ we have removed them and now have a clean dataset. Now we’ve got a dataset that should cover all the pale ales that were included in the main dataset, but we can refine it a little bit more. Let’s say pigs started to fly and I became picky about my choice of beer. I now only like beers that have been rated 4.5/5.0 or higher, and that have an ABV (alcohol by volume) equal to or between 5.0–6.0%. The code would look like this:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/shane-warne-glass-royal-ascot-1.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sierra Nevada Pale Ale          1367\n",
      "60 Minute IPA                   1141\n",
      "Alpha King Pale Ale              918\n",
      "Samuel Smith's Nut Brown Ale     604\n",
      "Anchor Liberty Ale               559\n",
      "                                ... \n",
      "Hammerhead Red Ale                 1\n",
      "Kimono Girl                        1\n",
      "Heritage Pale Ale                  1\n",
      "Wineglass Bay Hazards Ale          1\n",
      "Tanlines                           1\n",
      "Name: beer_name, Length: 3121, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#assigning the same variable just overwrites the values, here we are only selecting the rows that have values \n",
    "#equal to or higher than 4.5 in the 'review_overall' columns\n",
    "fav_beer_clean = fav_beer_clean[fav_beer_clean['review_overall']>=4.5]\n",
    "\n",
    "#this is similar to above, except this time we are using the 'beer_abv' column and adding a second conditional \n",
    "#statement using the '&' symbol\n",
    "fav_beer_clean = fav_beer_clean[(fav_beer_clean['beer_abv']>=5.0)&(fav_beer_clean['beer_abv']<=6.0)]\n",
    "\n",
    "#printing the value counts of different beers in the beer_name col\n",
    "print(fav_beer_clean['beer_name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see after doing this we have decreased our data frame size significantly. We are now only looking at 3121 different types of beer, which is still a lot to taste. I want to shorten my list to only be the 15 most reviewed beers so I know that a lot of people have tried them. To do this I would do as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sierra Nevada Pale Ale                       1367\n",
      "60 Minute IPA                                1141\n",
      "Alpha King Pale Ale                           918\n",
      "Samuel Smith's Nut Brown Ale                  604\n",
      "Anchor Liberty Ale                            559\n",
      "Bell's Oberon Ale                             548\n",
      "Masala Mama India Pale Ale                    486\n",
      "Tröegs Hopback Amber Ale                      456\n",
      "Duchesse De Bourgogne                         419\n",
      "Fat Tire Amber Ale                            393\n",
      "Great Lakes Burning River Pale Ale            381\n",
      "Sierra Nevada Anniversary Ale (2007-2009)     376\n",
      "Rodenbach Grand Cru                           373\n",
      "Bender                                        372\n",
      "Brutal Bitter Ale                             372\n",
      "Name: beer_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#putting the number 15 inside the '.head()' module sets the amount of returned rows to 15, as the value_count is \n",
    "#in ascending order it returns the top 15 most rated beers\n",
    "top_15 = fav_beer_clean['beer_name'].value_counts().head(15)\n",
    "\n",
    "print(top_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final list of the 15 most rated beers that fit the criteria of what I described to pandas. In conclusion we can see that clearly not enough people drink and review Coopers Pale Ale. Regardless, this is an example of how large datasets can be manipulated and analysed using pandas in python. We got a desired outcome without needing too much computing power, which would have been a different story if we had of tried to manipulate and analyse this file in Excel. Time for a pint."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Paris-Hilton-Drinks-Her-First-40oz-Beer-GGN-News-S4-Ep-5.png\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
