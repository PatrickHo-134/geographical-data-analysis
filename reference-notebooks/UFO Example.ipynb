{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UFO Sighting and Data Preprocessing - DataCamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a data cleaning workflow, using a UFO sighting dataset. It looks at various ways of cleaning data and how to best prepare your training/test sets for model creation. With the clean data we will predict which country any given UFO sighting took place between the USA and Canada."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/ufo.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>seconds</th>\n",
       "      <th>length_of_time</th>\n",
       "      <th>desc</th>\n",
       "      <th>recorded</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11/3/2011 19:21</td>\n",
       "      <td>woodville</td>\n",
       "      <td>wi</td>\n",
       "      <td>us</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1209600.0</td>\n",
       "      <td>2 weeks</td>\n",
       "      <td>Red blinking objects similar to airplanes or s...</td>\n",
       "      <td>12/12/2011</td>\n",
       "      <td>44.9530556</td>\n",
       "      <td>-92.291111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10/3/2004 19:05</td>\n",
       "      <td>cleveland</td>\n",
       "      <td>oh</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30sec.</td>\n",
       "      <td>Many fighter jets flying towards UFO</td>\n",
       "      <td>10/27/2004</td>\n",
       "      <td>41.4994444</td>\n",
       "      <td>-81.695556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9/25/2009 21:00</td>\n",
       "      <td>coon rapids</td>\n",
       "      <td>mn</td>\n",
       "      <td>us</td>\n",
       "      <td>cigar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green&amp;#44 red&amp;#44 and blue pulses of light tha...</td>\n",
       "      <td>12/12/2009</td>\n",
       "      <td>45.1200000</td>\n",
       "      <td>-93.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11/21/2002 05:45</td>\n",
       "      <td>clemmons</td>\n",
       "      <td>nc</td>\n",
       "      <td>us</td>\n",
       "      <td>triangle</td>\n",
       "      <td>300.0</td>\n",
       "      <td>about 5 minutes</td>\n",
       "      <td>It was a large&amp;#44 triangular shaped flying ob...</td>\n",
       "      <td>12/23/2002</td>\n",
       "      <td>36.0213889</td>\n",
       "      <td>-80.382222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8/19/2010 12:55</td>\n",
       "      <td>calgary (canada)</td>\n",
       "      <td>ab</td>\n",
       "      <td>ca</td>\n",
       "      <td>oval</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A white spinning disc in the shape of an oval.</td>\n",
       "      <td>8/24/2010</td>\n",
       "      <td>51.083333</td>\n",
       "      <td>-114.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6/16/2012 23:00</td>\n",
       "      <td>san diego</td>\n",
       "      <td>ca</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10 minutes</td>\n",
       "      <td>Dancing lights that would fly around and then ...</td>\n",
       "      <td>7/4/2012</td>\n",
       "      <td>32.7152778</td>\n",
       "      <td>-117.156389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7/12/2009 21:30</td>\n",
       "      <td>duluth</td>\n",
       "      <td>mn</td>\n",
       "      <td>us</td>\n",
       "      <td>oval</td>\n",
       "      <td>600.0</td>\n",
       "      <td>total? maybe around 10 mi</td>\n",
       "      <td>A minor amber color trail&amp;#44 (from where we w...</td>\n",
       "      <td>3/13/2012</td>\n",
       "      <td>46.7833333</td>\n",
       "      <td>-92.106389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10/20/2008 18:30</td>\n",
       "      <td>fairfield</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>several sightings from 10</td>\n",
       "      <td>Multiple sightings in Central Texas (Freestone...</td>\n",
       "      <td>1/10/2009</td>\n",
       "      <td>31.7244444</td>\n",
       "      <td>-96.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6/9/2013 00:00</td>\n",
       "      <td>oakville (canada)</td>\n",
       "      <td>on</td>\n",
       "      <td>ca</td>\n",
       "      <td>light</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>Brilliant orange light or chinese lantern at o...</td>\n",
       "      <td>7/3/2013</td>\n",
       "      <td>43.433333</td>\n",
       "      <td>-79.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4/26/2013 23:27</td>\n",
       "      <td>lacey</td>\n",
       "      <td>wa</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>Bright red light moving north to north west fr...</td>\n",
       "      <td>5/15/2013</td>\n",
       "      <td>47.0344444</td>\n",
       "      <td>-122.821944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date               city state country      type    seconds  \\\n",
       "0   11/3/2011 19:21          woodville    wi      us   unknown  1209600.0   \n",
       "1   10/3/2004 19:05          cleveland    oh      us    circle       30.0   \n",
       "2   9/25/2009 21:00        coon rapids    mn      us     cigar        0.0   \n",
       "3  11/21/2002 05:45           clemmons    nc      us  triangle      300.0   \n",
       "4   8/19/2010 12:55   calgary (canada)    ab      ca      oval        0.0   \n",
       "5   6/16/2012 23:00          san diego    ca      us     light      600.0   \n",
       "6   7/12/2009 21:30             duluth    mn      us      oval      600.0   \n",
       "7  10/20/2008 18:30          fairfield    tx      us     other        0.0   \n",
       "8    6/9/2013 00:00  oakville (canada)    on      ca     light      120.0   \n",
       "9   4/26/2013 23:27              lacey    wa      us     light      120.0   \n",
       "\n",
       "              length_of_time  \\\n",
       "0                    2 weeks   \n",
       "1                     30sec.   \n",
       "2                        NaN   \n",
       "3            about 5 minutes   \n",
       "4                          2   \n",
       "5                 10 minutes   \n",
       "6  total? maybe around 10 mi   \n",
       "7  several sightings from 10   \n",
       "8                  2 minutes   \n",
       "9                  2 minutes   \n",
       "\n",
       "                                                desc    recorded         lat  \\\n",
       "0  Red blinking objects similar to airplanes or s...  12/12/2011  44.9530556   \n",
       "1               Many fighter jets flying towards UFO  10/27/2004  41.4994444   \n",
       "2  Green&#44 red&#44 and blue pulses of light tha...  12/12/2009  45.1200000   \n",
       "3  It was a large&#44 triangular shaped flying ob...  12/23/2002  36.0213889   \n",
       "4     A white spinning disc in the shape of an oval.   8/24/2010   51.083333   \n",
       "5  Dancing lights that would fly around and then ...    7/4/2012  32.7152778   \n",
       "6  A minor amber color trail&#44 (from where we w...   3/13/2012  46.7833333   \n",
       "7  Multiple sightings in Central Texas (Freestone...   1/10/2009  31.7244444   \n",
       "8  Brilliant orange light or chinese lantern at o...    7/3/2013   43.433333   \n",
       "9  Bright red light moving north to north west fr...   5/15/2013  47.0344444   \n",
       "\n",
       "         long  \n",
       "0  -92.291111  \n",
       "1  -81.695556  \n",
       "2  -93.287500  \n",
       "3  -80.382222  \n",
       "4 -114.083333  \n",
       "5 -117.156389  \n",
       "6  -92.106389  \n",
       "7  -96.165000  \n",
       "8  -79.666667  \n",
       "9 -122.821944  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Loading the dataset, found on DataCamp website\n",
    "ufo = pd.read_csv('PATH TO CSV')\n",
    "\n",
    "#First pass look at the data\n",
    "ufo.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table contains datetime, categorical, text and numeric data. A lot of cleaning is going to have to be done here to create a usable dataset. First lets look at the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               object\n",
       "city               object\n",
       "state              object\n",
       "country            object\n",
       "type               object\n",
       "seconds           float64\n",
       "length_of_time     object\n",
       "desc               object\n",
       "recorded           object\n",
       "lat                object\n",
       "long              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the column types\n",
    "ufo.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'date' feature in the dataframd is of type 'object'. We should change this to 'datetime' for better accessibilty to the data it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the date column to type datetime\n",
    "ufo[\"date\"] = pd.to_datetime(ufo['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the column types\n",
    "ufo[['date']].dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/cantina.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for and Removing Rows with Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data types are everything we want them to be, we should look for missing values in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4935 entries, 0 to 4934\n",
      "Data columns (total 11 columns):\n",
      "date              4935 non-null datetime64[ns]\n",
      "city              4926 non-null object\n",
      "state             4516 non-null object\n",
      "country           4255 non-null object\n",
      "type              4776 non-null object\n",
      "seconds           4935 non-null float64\n",
      "length_of_time    4792 non-null object\n",
      "desc              4932 non-null object\n",
      "recorded          4935 non-null object\n",
      "lat               4935 non-null object\n",
      "long              4935 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(2), object(8)\n",
      "memory usage: 424.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Looking for missing values\n",
    "ufo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 11 features, only 5 features have no missing values with a total of 4935 elements in their columns. Here we will remove all rows where we know the length of time the UFO was seen, the state it was in and what type of UFO it was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows where length_of_time, state, and type are not null\n",
    "ufo = ufo[ufo['length_of_time'].notnull() & \n",
    "          ufo['state'].notnull() & \n",
    "          ufo['type'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the length of time is in different units, we will create a new column that contains the units, and remove all the rows where the units are Null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>seconds</th>\n",
       "      <th>length_of_time</th>\n",
       "      <th>desc</th>\n",
       "      <th>recorded</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>time_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2011-11-03 19:21:00</td>\n",
       "      <td>woodville</td>\n",
       "      <td>wi</td>\n",
       "      <td>us</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1209600.0</td>\n",
       "      <td>2 weeks</td>\n",
       "      <td>Red blinking objects similar to airplanes or s...</td>\n",
       "      <td>12/12/2011</td>\n",
       "      <td>44.9530556</td>\n",
       "      <td>-92.291111</td>\n",
       "      <td>weeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2004-10-03 19:05:00</td>\n",
       "      <td>cleveland</td>\n",
       "      <td>oh</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30sec.</td>\n",
       "      <td>Many fighter jets flying towards UFO</td>\n",
       "      <td>10/27/2004</td>\n",
       "      <td>41.4994444</td>\n",
       "      <td>-81.695556</td>\n",
       "      <td>seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2002-11-21 05:45:00</td>\n",
       "      <td>clemmons</td>\n",
       "      <td>nc</td>\n",
       "      <td>us</td>\n",
       "      <td>triangle</td>\n",
       "      <td>300.0</td>\n",
       "      <td>about 5 minutes</td>\n",
       "      <td>It was a large&amp;#44 triangular shaped flying ob...</td>\n",
       "      <td>12/23/2002</td>\n",
       "      <td>36.0213889</td>\n",
       "      <td>-80.382222</td>\n",
       "      <td>minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2010-08-19 12:55:00</td>\n",
       "      <td>calgary (canada)</td>\n",
       "      <td>ab</td>\n",
       "      <td>ca</td>\n",
       "      <td>oval</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A white spinning disc in the shape of an oval.</td>\n",
       "      <td>8/24/2010</td>\n",
       "      <td>51.083333</td>\n",
       "      <td>-114.083333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2012-06-16 23:00:00</td>\n",
       "      <td>san diego</td>\n",
       "      <td>ca</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10 minutes</td>\n",
       "      <td>Dancing lights that would fly around and then ...</td>\n",
       "      <td>7/4/2012</td>\n",
       "      <td>32.7152778</td>\n",
       "      <td>-117.156389</td>\n",
       "      <td>minutes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date              city state country      type    seconds  \\\n",
       "0 2011-11-03 19:21:00         woodville    wi      us   unknown  1209600.0   \n",
       "1 2004-10-03 19:05:00         cleveland    oh      us    circle       30.0   \n",
       "3 2002-11-21 05:45:00          clemmons    nc      us  triangle      300.0   \n",
       "4 2010-08-19 12:55:00  calgary (canada)    ab      ca      oval        0.0   \n",
       "5 2012-06-16 23:00:00         san diego    ca      us     light      600.0   \n",
       "\n",
       "    length_of_time                                               desc  \\\n",
       "0          2 weeks  Red blinking objects similar to airplanes or s...   \n",
       "1           30sec.               Many fighter jets flying towards UFO   \n",
       "3  about 5 minutes  It was a large&#44 triangular shaped flying ob...   \n",
       "4                2     A white spinning disc in the shape of an oval.   \n",
       "5       10 minutes  Dancing lights that would fly around and then ...   \n",
       "\n",
       "     recorded         lat        long time_units  \n",
       "0  12/12/2011  44.9530556  -92.291111      weeks  \n",
       "1  10/27/2004  41.4994444  -81.695556    seconds  \n",
       "3  12/23/2002  36.0213889  -80.382222    minutes  \n",
       "4   8/24/2010   51.083333 -114.083333        NaN  \n",
       "5    7/4/2012  32.7152778 -117.156389    minutes  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a column that contains the units from the 'length of time' column\n",
    "ufo.loc[ufo['length_of_time'].str.contains('sec'), 'time_units'] = 'seconds'\n",
    "ufo.loc[ufo['length_of_time'].str.contains('min'), 'time_units'] = 'minutes'\n",
    "ufo.loc[ufo['length_of_time'].str.contains('week'), 'time_units'] = 'weeks'\n",
    "\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3406, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo = ufo.dropna()\n",
    "\n",
    "ufo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaining Time Values from The Time Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'lengths of time' column contains different string characters. In this step we will look at extracting the values of time from all possible UFO sighting times using the regular expression package, more can be found on that [here](https://www.w3schools.com/python/python_regex.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import regular expression operations\n",
    "import re\n",
    "\n",
    "#Defining a function that returns the minute values\n",
    "def return_time_values(time_string):\n",
    "\n",
    "    # Use \\d+ to grab digits\n",
    "    pattern = re.compile(r\"\\d+\")\n",
    "    \n",
    "    # Use match on the pattern and column\n",
    "    num = re.match(pattern, time_string)\n",
    "    if num is not None:\n",
    "        return int(num.group(0))\n",
    "        \n",
    "# Apply the extraction to the length_of_time column\n",
    "ufo[\"time_values\"] = ufo[\"length_of_time\"].apply(lambda row: return_time_values(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     length_of_time  time_values time_units\n",
      "0           2 weeks          2.0      weeks\n",
      "1            30sec.         30.0    seconds\n",
      "3   about 5 minutes          NaN    minutes\n",
      "5        10 minutes         10.0    minutes\n",
      "8         2 minutes          2.0    minutes\n",
      "9         2 minutes          2.0    minutes\n",
      "10        5 minutes          5.0    minutes\n",
      "11       10 minutes         10.0    minutes\n",
      "12            2 min          2.0    minutes\n",
      "13       30 seconds         30.0    seconds\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the head of both of the columns\n",
    "print(ufo[['length_of_time', 'time_values', 'time_units']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the time values we can perform a conversion on them based upon their unit to determine what the time would be in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3148, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the minutes column\n",
    "ufo.loc[ufo['time_units'] == 'seconds', 'minutes'] = ufo['time_values']/60\n",
    "ufo.loc[ufo['time_units'] == 'minutes', 'minutes'] = ufo['time_values']\n",
    "ufo.loc[ufo['time_units'] == 'weeks', 'minutes'] = ufo['time_values']*10080 \n",
    "\n",
    "#removing the NaN values\n",
    "ufo = ufo.dropna()\n",
    "\n",
    "ufo.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/waiting.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Log Normalisation to Features with Large Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can apply a normalisation to some features. Let's look at the variance of two of our features, the given 'seconds' feature and recently created 'time_min' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds    1.509768e+09\n",
      "minutes    4.193635e+05\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check the variance of the seconds and minutes columns\n",
    "print(ufo[['seconds', 'minutes']].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see there is a huge variance in both the seconds and the minutes column (which makes sense as there were sightings reported from seconds up to weeks of UFO sightings). To make this variance more ML friendly we apply a log normalisation to the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/series.py:853: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Log normalize the seconds column\n",
    "ufo[\"seconds_log\"] = np.log(ufo['seconds'])\n",
    "ufo[\"minutes_log\"] = np.log(ufo['minutes'])\n",
    "\n",
    "#Replacing any Infinite values with NaN\n",
    "ufo[\"seconds_log\"] = ufo['seconds_log'].replace([np.inf, -np.inf], np.nan)\n",
    "ufo[\"minutes_log\"] = ufo['minutes_log'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the null values \n",
    "ufo = ufo[pd.notnull(ufo['seconds_log'])]\n",
    "ufo = ufo[pd.notnull(ufo['minutes_log'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds_log    3.831132\n",
      "minutes_log    3.885088\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print out the variance of the normalised columns\n",
    "print(ufo[[\"seconds_log\", 'minutes_log']].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see there is a significant decrease in the variation between the two features. More information about scaling can be found [here](https://developers.google.com/machine-learning/data-prep/transform/normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Encoders on Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will look at turning Categorical features into numerical by using an encoder. More can be found here. First we will encode the countries as 1 or 0 for USA or Canada, and then encode the type of UFO seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to encode us values as 1 and others as 0\n",
    "ufo[\"country_enc\"] = ufo[\"country\"].apply(lambda x: 1 if x=='us' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# Print the number of unique type values\n",
    "print(len(ufo['type'].unique()))\n",
    "\n",
    "# Create a one-hot encoded set of the type values\n",
    "type_set = pd.get_dummies(ufo['type'])\n",
    "\n",
    "# Concatenate this set back to the ufo DataFrame\n",
    "ufo = pd.concat([ufo, type_set], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21 features have been added to the DataFrame, representing the 'type' of UFO seen. More information on feature encoding can be found [here](https://towardsdatascience.com/encoding-categorical-features-21a2651a065c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Time to Months and Years Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert the datatime column to have a look at the month and year variables independently. This can be done quite easily with python, and is explained [here](http://docs.python.org/2/library/datetime.html#datetime.datetime.strptime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2011-11-03 19:21:00\n",
      "1   2004-10-03 19:05:00\n",
      "5   2012-06-16 23:00:00\n",
      "8   2013-06-09 00:00:00\n",
      "9   2013-04-26 23:27:00\n",
      "Name: date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Look at the first 5 rows of the date column\n",
    "print(ufo['date'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  month  year\n",
      "0 2011-11-03 19:21:00     11  2011\n",
      "1 2004-10-03 19:05:00     10  2004\n",
      "5 2012-06-16 23:00:00      6  2012\n",
      "8 2013-06-09 00:00:00      6  2013\n",
      "9 2013-04-26 23:27:00      4  2013\n"
     ]
    }
   ],
   "source": [
    "# Extract the month from the date column\n",
    "ufo[\"month\"] = ufo[\"date\"].apply(lambda row: row.month)\n",
    "\n",
    "# Extract the year from the date column\n",
    "ufo[\"year\"] = ufo[\"date\"].apply(lambda row: row.year)\n",
    "\n",
    "# Take a look at the head of all three columns\n",
    "print(ufo[['date', 'month', 'year']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/alienpad.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Features we Don't Need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the features are all clean it's time to decide which features the model will be built on. For the first step we'll assess the correlations between the seconds and minutes columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              seconds  seconds_log   minutes  minutes_log\n",
      "seconds      1.000000     0.131936  0.999965     0.131503\n",
      "seconds_log  0.131936     1.000000  0.130681     0.988823\n",
      "minutes      0.999965     0.130681  1.000000     0.131115\n",
      "minutes_log  0.131503     0.988823  0.131115     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Check the correlation between the seconds, seconds_log, and minutes columns\n",
    "print(ufo[['seconds', 'seconds_log', 'minutes', 'minutes_log']].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that there is a strong correlation between the seconds-minutes (for log scaled too). This makes sense as they're measurements of the same thing. In this case we can drop all but 1 time feature. Next we can look at other potential columns to drop and get rid of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'city', 'state', 'country', 'type', 'seconds', 'length_of_time',\n",
       "       'desc', 'recorded', 'lat', 'long', 'time_units', 'time_values',\n",
       "       'minutes', 'seconds_log', 'minutes_log', 'country_enc', 'changing',\n",
       "       'chevron', 'cigar', 'circle', 'cone', 'cross', 'cylinder', 'diamond',\n",
       "       'disk', 'egg', 'fireball', 'flash', 'formation', 'light', 'other',\n",
       "       'oval', 'rectangle', 'sphere', 'teardrop', 'triangle', 'unknown',\n",
       "       'month', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analysing the columns we have in the dataframe\n",
    "ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['minutes_log', 'country_enc', 'changing', 'chevron', 'cigar', 'circle',\n",
       "       'cone', 'cross', 'cylinder', 'diamond', 'disk', 'egg', 'fireball',\n",
       "       'flash', 'formation', 'light', 'other', 'oval', 'rectangle', 'sphere',\n",
       "       'teardrop', 'triangle', 'unknown', 'month', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a list of features to drop\n",
    "to_drop = ['date', 'city', 'country', 'state', 'type', 'seconds', 'length_of_time', 'desc', 'recorded', 'lat', 'long', 'time_units', 'time_values', 'minutes', 'seconds_log']\n",
    "\n",
    "# Drop those features\n",
    "ufo_dropped = ufo.drop(to_drop, axis=1)\n",
    "\n",
    "ufo_dropped.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see all the features that remain after we've removed features we deem insignificant. From this we can create the model. In this case a K-Nearest-Neighbor classifier was selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/trump-ufo.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting features\n",
    "X = ufo_dropped[['minutes_log', 'changing', 'chevron', 'cigar', 'circle',\n",
    "       'cone', 'cross', 'cylinder', 'diamond', 'disk', 'egg', 'fireball',\n",
    "       'flash', 'formation', 'light', 'other', 'oval', 'rectangle', 'sphere',\n",
    "       'teardrop', 'triangle', 'unknown', 'month', 'year']]\n",
    "\n",
    "#Subsetting the target variable\n",
    "y = ufo_dropped['country_enc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have split features we can create a model that classifies whether a UFO was spotted in the USA or in Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the X and y sets using train_test_split, setting stratify=y\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9491740787801779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Fit knn to the training sets\n",
    "knn.fit(train_X, train_y)\n",
    "\n",
    "# Print the score of knn on the test sets\n",
    "print(knn.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model returned a great accuracy of 95%. All data and workflow was based on the Preprocessing for Machine Learning in Python course on DataCamp."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
